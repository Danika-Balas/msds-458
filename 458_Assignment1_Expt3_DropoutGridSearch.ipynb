{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "458_Assignment1_Expt3.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMrrz1iPKfds0VUucOma5sO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Danika-Balas/msds-458/blob/master/458_Assignment1_Expt3_DropoutGridSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tlSigYwlVuKR",
        "colab_type": "text"
      },
      "source": [
        "##Setup and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D8jpVsoTpY4",
        "colab_type": "code",
        "outputId": "86a7591b-96a7-4144-eac3-61207dab3faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "keras.__version__"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.3.0-tf'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZZtq6bpWITd",
        "colab_type": "code",
        "outputId": "e3609673-caf5-4feb-d1bb-9d032bf4ce24",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.2.0-rc3'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rp2_1vRkVgVJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras import metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BO5dsO7-WLFE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# neccessary for K.gradient to work in TensorFlow 2.x\n",
        "# only needed for the \"Finding a pattern the hidden node maximally responds to\" section below.\n",
        "# but disabled to make Tensorboard work...\n",
        "tf.compat.v1.disable_eager_execution() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fTtBYXtHWztP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set see in order to achieve consistent results across runs\n",
        "keras.backend.clear_session()\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpqFxPDEXFup",
        "colab_type": "text"
      },
      "source": [
        "####Import MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65M8kDjCXA0p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.datasets import mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ye8BcA0XYvH",
        "colab_type": "code",
        "outputId": "2b1c59e1-1674-4365-c1e4-3bf443c687ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train_images.shape, test_images.shape, test_labels.shape, test_labels.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28), (10000,), (10000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5gJtcFsOpHi",
        "colab_type": "code",
        "outputId": "ed99ef3a-022e-408d-9716-a650a70cf7e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Store copy of training images in order to easily view images even after transformation are performed\n",
        "example_train_images = train_images.copy()\n",
        "example_train_images.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJIB5WuVXwK2",
        "colab_type": "code",
        "outputId": "718677aa-e279-4150-c4be-8d4c866e9542",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        }
      },
      "source": [
        "# Example of a single sample, a 28x28 pixel image of a handwritten digit\n",
        "digit = example_train_images[2]\n",
        "\n",
        "plt.imshow(digit, cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nsn_iI4MqBtg",
        "colab_type": "text"
      },
      "source": [
        "####Prepare the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ME7Vm7GYCwq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reshape the data into the shape that the network expects\n",
        "train_images = train_images.reshape((60000, 28 * 28))\n",
        "\n",
        "# Scale the data to [0,1] interval\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "# Do the same for the test dataset\n",
        "test_images = test_images.reshape((10000, 28 * 28))\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElgA23UFq0lB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Split training data into training set and validation set\n",
        "val_images, train_images = train_images[:5000], train_images[5000:]\n",
        "val_labels, train_labels = train_labels[:5000], train_labels[5000:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fmDzWxIu78_L",
        "colab_type": "text"
      },
      "source": [
        "#Experiment 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5_ueNa18nef",
        "colab_type": "text"
      },
      "source": [
        "We will fine-tune the hyperparameters of the model until we find the 'best' model according to our selected metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqLphCVo8D9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function builds models with 1 hidden layer (by default), then the same number of nodes in each hidden layer\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_model(n_hidden=1, n_neurons=2, learning_rate=0.001, input_shape=(28 * 28,)):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape=input_shape))\n",
        "    model.add(keras.layers.Dense(85, activation=\"relu\"))\n",
        "    for layer in range(n_hidden):\n",
        "        model.add(keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dropout(0.25))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer,  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8yORVMj93Hv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This function builds models with varying number of nodes in each hidden layer\n",
        "def build_model2(n_neurons=(2,3), learning_rate=0.001, input_shape=(28 * 28,)):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape=input_shape))\n",
        "    for layer in range(len(n_neurons)):\n",
        "        model.add(keras.layers.Dense(n_neurons[layer], activation=\"relu\"))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer,  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWNTDtmilzlI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Function builds models with 1 hidden layer (by default), then the same number of nodes in each hidden layer\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "def build_model3(n_hidden=1, n_neurons=2, learning_rate=0.001, input_shape=(28 * 28,), n_dropout=0.05):\n",
        "    model = models.Sequential()\n",
        "    model.add(layers.InputLayer(input_shape=input_shape))\n",
        "    model.add(keras.layers.Dense(110, activation=\"relu\"))\n",
        "    model.add(keras.layers.Dropout(n_dropout))\n",
        "    model.add(layers.Dense(10, activation='softmax'))\n",
        "    optimizer = keras.optimizers.Adam(lr=learning_rate)\n",
        "    model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizer,  metrics=['accuracy'])\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m40FBZQsFRlD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "keras_clf = KerasClassifier(build_model3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3DYgnj-FY6k",
        "colab_type": "code",
        "outputId": "5f28d910-d7b0-4a5d-dc03-837dd09274c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#param_grid = {'n_neurons': range(680,720,5)}\n",
        "param_grid = {'n_dropout': (0,0.05,0.1,0.15,0.2,0.25,0.3)}\n",
        "param_grid"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_dropout': (0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elLBPW5OF27j",
        "colab_type": "text"
      },
      "source": [
        "Use grid search to train models with different combinations of parameter values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crzvlHtkNm3n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6aaa93a8-7ee6-469f-a728-8a3167e5f83b"
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "grid_cv = GridSearchCV(estimator=keras_clf, param_grid=param_grid,cv=3,verbose = 2)\n",
        "grid_cv.fit(train_images, train_labels, epochs=30,\n",
        "                  validation_data=(val_images, val_labels),\n",
        "                  callbacks=[keras.callbacks.EarlyStopping(patience=2)])"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
            "[CV] n_dropout=0 .....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 36666 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36666/36666 [==============================] - 4s 121us/sample - loss: 0.3285 - accuracy: 0.9073 - val_loss: 0.1801 - val_accuracy: 0.9510\n",
            "Epoch 2/30\n",
            "36666/36666 [==============================] - 4s 110us/sample - loss: 0.1547 - accuracy: 0.9550 - val_loss: 0.1321 - val_accuracy: 0.9638\n",
            "Epoch 3/30\n",
            "36666/36666 [==============================] - 4s 116us/sample - loss: 0.1062 - accuracy: 0.9690 - val_loss: 0.1065 - val_accuracy: 0.9684\n",
            "Epoch 4/30\n",
            "36666/36666 [==============================] - 4s 108us/sample - loss: 0.0803 - accuracy: 0.9753 - val_loss: 0.1023 - val_accuracy: 0.9678\n",
            "Epoch 5/30\n",
            "36666/36666 [==============================] - 4s 108us/sample - loss: 0.0621 - accuracy: 0.9807 - val_loss: 0.0981 - val_accuracy: 0.9724\n",
            "Epoch 6/30\n",
            "36666/36666 [==============================] - 4s 106us/sample - loss: 0.0493 - accuracy: 0.9851 - val_loss: 0.0940 - val_accuracy: 0.9726\n",
            "Epoch 7/30\n",
            "36666/36666 [==============================] - 4s 109us/sample - loss: 0.0398 - accuracy: 0.9881 - val_loss: 0.0947 - val_accuracy: 0.9708\n",
            "Epoch 8/30\n",
            "36666/36666 [==============================] - 4s 113us/sample - loss: 0.0319 - accuracy: 0.9907 - val_loss: 0.0873 - val_accuracy: 0.9750\n",
            "Epoch 9/30\n",
            "36666/36666 [==============================] - 4s 114us/sample - loss: 0.0269 - accuracy: 0.9918 - val_loss: 0.1007 - val_accuracy: 0.9702\n",
            "Epoch 10/30\n",
            "36666/36666 [==============================] - 4s 108us/sample - loss: 0.0192 - accuracy: 0.9949 - val_loss: 0.0991 - val_accuracy: 0.9704\n",
            "[CV] ...................................... n_dropout=0, total=  42.4s\n",
            "[CV] n_dropout=0 .....................................................\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   42.4s remaining:    0.0s\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 36667 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36667/36667 [==============================] - 4s 115us/sample - loss: 0.3250 - accuracy: 0.9082 - val_loss: 0.1799 - val_accuracy: 0.9532\n",
            "Epoch 2/30\n",
            "36667/36667 [==============================] - 4s 111us/sample - loss: 0.1504 - accuracy: 0.9567 - val_loss: 0.1318 - val_accuracy: 0.9646\n",
            "Epoch 3/30\n",
            "36667/36667 [==============================] - 4s 111us/sample - loss: 0.1056 - accuracy: 0.9685 - val_loss: 0.1107 - val_accuracy: 0.9676\n",
            "Epoch 4/30\n",
            "36667/36667 [==============================] - 4s 106us/sample - loss: 0.0793 - accuracy: 0.9763 - val_loss: 0.0981 - val_accuracy: 0.9716\n",
            "Epoch 5/30\n",
            "36667/36667 [==============================] - 4s 111us/sample - loss: 0.0596 - accuracy: 0.9823 - val_loss: 0.0987 - val_accuracy: 0.9688\n",
            "Epoch 6/30\n",
            "36667/36667 [==============================] - 4s 105us/sample - loss: 0.0473 - accuracy: 0.9855 - val_loss: 0.0904 - val_accuracy: 0.9740\n",
            "Epoch 7/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0381 - accuracy: 0.9888 - val_loss: 0.0849 - val_accuracy: 0.9764\n",
            "Epoch 8/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.0297 - accuracy: 0.9911 - val_loss: 0.0966 - val_accuracy: 0.9724\n",
            "Epoch 9/30\n",
            "36667/36667 [==============================] - 4s 107us/sample - loss: 0.0237 - accuracy: 0.9927 - val_loss: 0.0868 - val_accuracy: 0.9760\n",
            "[CV] ...................................... n_dropout=0, total=  37.7s\n",
            "[CV] n_dropout=0 .....................................................\n",
            "Train on 36667 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36667/36667 [==============================] - 4s 114us/sample - loss: 0.3294 - accuracy: 0.9076 - val_loss: 0.1785 - val_accuracy: 0.9498\n",
            "Epoch 2/30\n",
            "36667/36667 [==============================] - 4s 110us/sample - loss: 0.1503 - accuracy: 0.9561 - val_loss: 0.1400 - val_accuracy: 0.9620\n",
            "Epoch 3/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.1053 - accuracy: 0.9687 - val_loss: 0.1207 - val_accuracy: 0.9638\n",
            "Epoch 4/30\n",
            "36667/36667 [==============================] - 4s 111us/sample - loss: 0.0790 - accuracy: 0.9764 - val_loss: 0.0960 - val_accuracy: 0.9718\n",
            "Epoch 5/30\n",
            "36667/36667 [==============================] - 4s 111us/sample - loss: 0.0599 - accuracy: 0.9822 - val_loss: 0.0991 - val_accuracy: 0.9714\n",
            "Epoch 6/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0485 - accuracy: 0.9857 - val_loss: 0.0935 - val_accuracy: 0.9718\n",
            "Epoch 7/30\n",
            "36667/36667 [==============================] - 4s 113us/sample - loss: 0.0381 - accuracy: 0.9890 - val_loss: 0.0871 - val_accuracy: 0.9748\n",
            "Epoch 8/30\n",
            "36667/36667 [==============================] - 4s 109us/sample - loss: 0.0304 - accuracy: 0.9913 - val_loss: 0.0933 - val_accuracy: 0.9748\n",
            "Epoch 9/30\n",
            "36667/36667 [==============================] - 4s 113us/sample - loss: 0.0245 - accuracy: 0.9930 - val_loss: 0.0960 - val_accuracy: 0.9736\n",
            "[CV] ...................................... n_dropout=0, total=  38.5s\n",
            "[CV] n_dropout=0.05 ..................................................\n",
            "Train on 36666 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36666/36666 [==============================] - 4s 122us/sample - loss: 0.3366 - accuracy: 0.9050 - val_loss: 0.1743 - val_accuracy: 0.9512\n",
            "Epoch 2/30\n",
            "36666/36666 [==============================] - 4s 113us/sample - loss: 0.1601 - accuracy: 0.9528 - val_loss: 0.1367 - val_accuracy: 0.9616\n",
            "Epoch 3/30\n",
            "36666/36666 [==============================] - 4s 117us/sample - loss: 0.1123 - accuracy: 0.9665 - val_loss: 0.1123 - val_accuracy: 0.9662\n",
            "Epoch 4/30\n",
            "36666/36666 [==============================] - 4s 115us/sample - loss: 0.0889 - accuracy: 0.9742 - val_loss: 0.0974 - val_accuracy: 0.9696\n",
            "Epoch 5/30\n",
            "36666/36666 [==============================] - 4s 107us/sample - loss: 0.0711 - accuracy: 0.9785 - val_loss: 0.0977 - val_accuracy: 0.9702\n",
            "Epoch 6/30\n",
            "36666/36666 [==============================] - 4s 109us/sample - loss: 0.0585 - accuracy: 0.9816 - val_loss: 0.0855 - val_accuracy: 0.9760\n",
            "Epoch 7/30\n",
            "36666/36666 [==============================] - 4s 113us/sample - loss: 0.0487 - accuracy: 0.9847 - val_loss: 0.0975 - val_accuracy: 0.9700\n",
            "Epoch 8/30\n",
            "36666/36666 [==============================] - 4s 111us/sample - loss: 0.0416 - accuracy: 0.9872 - val_loss: 0.0923 - val_accuracy: 0.9730\n",
            "[CV] ................................... n_dropout=0.05, total=  34.9s\n",
            "[CV] n_dropout=0.05 ..................................................\n",
            "Train on 36667 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36667/36667 [==============================] - 4s 120us/sample - loss: 0.3474 - accuracy: 0.9000 - val_loss: 0.1842 - val_accuracy: 0.9506\n",
            "Epoch 2/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.1638 - accuracy: 0.9533 - val_loss: 0.1324 - val_accuracy: 0.9646\n",
            "Epoch 3/30\n",
            "36667/36667 [==============================] - 4s 117us/sample - loss: 0.1123 - accuracy: 0.9666 - val_loss: 0.1089 - val_accuracy: 0.9700\n",
            "Epoch 4/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.0868 - accuracy: 0.9732 - val_loss: 0.0910 - val_accuracy: 0.9724\n",
            "Epoch 5/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0691 - accuracy: 0.9789 - val_loss: 0.0891 - val_accuracy: 0.9724\n",
            "Epoch 6/30\n",
            "36667/36667 [==============================] - 4s 106us/sample - loss: 0.0565 - accuracy: 0.9824 - val_loss: 0.0967 - val_accuracy: 0.9702\n",
            "Epoch 7/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0448 - accuracy: 0.9858 - val_loss: 0.0814 - val_accuracy: 0.9758\n",
            "Epoch 8/30\n",
            "36667/36667 [==============================] - 4s 114us/sample - loss: 0.0402 - accuracy: 0.9873 - val_loss: 0.0869 - val_accuracy: 0.9756\n",
            "Epoch 9/30\n",
            "36667/36667 [==============================] - 4s 111us/sample - loss: 0.0334 - accuracy: 0.9894 - val_loss: 0.0901 - val_accuracy: 0.9722\n",
            "[CV] ................................... n_dropout=0.05, total=  38.7s\n",
            "[CV] n_dropout=0.05 ..................................................\n",
            "Train on 36667 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36667/36667 [==============================] - 4s 114us/sample - loss: 0.3449 - accuracy: 0.9009 - val_loss: 0.1738 - val_accuracy: 0.9520\n",
            "Epoch 2/30\n",
            "36667/36667 [==============================] - 4s 109us/sample - loss: 0.1607 - accuracy: 0.9527 - val_loss: 0.1285 - val_accuracy: 0.9638\n",
            "Epoch 3/30\n",
            "36667/36667 [==============================] - 4s 110us/sample - loss: 0.1127 - accuracy: 0.9652 - val_loss: 0.1039 - val_accuracy: 0.9704\n",
            "Epoch 4/30\n",
            "36667/36667 [==============================] - 4s 110us/sample - loss: 0.0860 - accuracy: 0.9737 - val_loss: 0.1051 - val_accuracy: 0.9684\n",
            "Epoch 5/30\n",
            "36667/36667 [==============================] - 4s 109us/sample - loss: 0.0687 - accuracy: 0.9785 - val_loss: 0.0967 - val_accuracy: 0.9704\n",
            "Epoch 6/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0568 - accuracy: 0.9821 - val_loss: 0.0848 - val_accuracy: 0.9742\n",
            "Epoch 7/30\n",
            "36667/36667 [==============================] - 4s 109us/sample - loss: 0.0487 - accuracy: 0.9843 - val_loss: 0.0909 - val_accuracy: 0.9734\n",
            "Epoch 8/30\n",
            "36667/36667 [==============================] - 4s 119us/sample - loss: 0.0403 - accuracy: 0.9874 - val_loss: 0.0897 - val_accuracy: 0.9742\n",
            "[CV] ................................... n_dropout=0.05, total=  34.4s\n",
            "[CV] n_dropout=0.1 ...................................................\n",
            "Train on 36666 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36666/36666 [==============================] - 4s 115us/sample - loss: 0.3499 - accuracy: 0.8982 - val_loss: 0.1769 - val_accuracy: 0.9504\n",
            "Epoch 2/30\n",
            "36666/36666 [==============================] - 4s 107us/sample - loss: 0.1692 - accuracy: 0.9499 - val_loss: 0.1266 - val_accuracy: 0.9656\n",
            "Epoch 3/30\n",
            "36666/36666 [==============================] - 4s 111us/sample - loss: 0.1221 - accuracy: 0.9641 - val_loss: 0.1047 - val_accuracy: 0.9688\n",
            "Epoch 4/30\n",
            "36666/36666 [==============================] - 4s 115us/sample - loss: 0.0952 - accuracy: 0.9712 - val_loss: 0.0962 - val_accuracy: 0.9720\n",
            "Epoch 5/30\n",
            "36666/36666 [==============================] - 4s 115us/sample - loss: 0.0786 - accuracy: 0.9759 - val_loss: 0.0893 - val_accuracy: 0.9752\n",
            "Epoch 6/30\n",
            "36666/36666 [==============================] - 4s 108us/sample - loss: 0.0651 - accuracy: 0.9802 - val_loss: 0.0900 - val_accuracy: 0.9734\n",
            "Epoch 7/30\n",
            "36666/36666 [==============================] - 4s 108us/sample - loss: 0.0550 - accuracy: 0.9831 - val_loss: 0.0855 - val_accuracy: 0.9732\n",
            "Epoch 8/30\n",
            "36666/36666 [==============================] - 4s 107us/sample - loss: 0.0468 - accuracy: 0.9854 - val_loss: 0.0831 - val_accuracy: 0.9744\n",
            "Epoch 9/30\n",
            "36666/36666 [==============================] - 4s 107us/sample - loss: 0.0421 - accuracy: 0.9864 - val_loss: 0.0846 - val_accuracy: 0.9764\n",
            "Epoch 10/30\n",
            "36666/36666 [==============================] - 4s 115us/sample - loss: 0.0377 - accuracy: 0.9879 - val_loss: 0.0789 - val_accuracy: 0.9784\n",
            "Epoch 11/30\n",
            "36666/36666 [==============================] - 4s 116us/sample - loss: 0.0309 - accuracy: 0.9897 - val_loss: 0.0824 - val_accuracy: 0.9752\n",
            "Epoch 12/30\n",
            "36666/36666 [==============================] - 4s 120us/sample - loss: 0.0289 - accuracy: 0.9908 - val_loss: 0.0901 - val_accuracy: 0.9756\n",
            "[CV] .................................... n_dropout=0.1, total=  51.2s\n",
            "[CV] n_dropout=0.1 ...................................................\n",
            "Train on 36667 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36667/36667 [==============================] - 4s 116us/sample - loss: 0.3442 - accuracy: 0.9003 - val_loss: 0.1756 - val_accuracy: 0.9490\n",
            "Epoch 2/30\n",
            "36667/36667 [==============================] - 4s 116us/sample - loss: 0.1639 - accuracy: 0.9517 - val_loss: 0.1290 - val_accuracy: 0.9652\n",
            "Epoch 3/30\n",
            "36667/36667 [==============================] - 4s 107us/sample - loss: 0.1194 - accuracy: 0.9638 - val_loss: 0.1158 - val_accuracy: 0.9664\n",
            "Epoch 4/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.0942 - accuracy: 0.9711 - val_loss: 0.0967 - val_accuracy: 0.9730\n",
            "Epoch 5/30\n",
            "36667/36667 [==============================] - 4s 113us/sample - loss: 0.0745 - accuracy: 0.9775 - val_loss: 0.0896 - val_accuracy: 0.9728\n",
            "Epoch 6/30\n",
            "36667/36667 [==============================] - 4s 114us/sample - loss: 0.0648 - accuracy: 0.9793 - val_loss: 0.0874 - val_accuracy: 0.9734\n",
            "Epoch 7/30\n",
            "36667/36667 [==============================] - 4s 110us/sample - loss: 0.0547 - accuracy: 0.9829 - val_loss: 0.0849 - val_accuracy: 0.9764\n",
            "Epoch 8/30\n",
            "36667/36667 [==============================] - 4s 107us/sample - loss: 0.0448 - accuracy: 0.9856 - val_loss: 0.0824 - val_accuracy: 0.9772\n",
            "Epoch 9/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.0390 - accuracy: 0.9876 - val_loss: 0.0818 - val_accuracy: 0.9782\n",
            "Epoch 10/30\n",
            "36667/36667 [==============================] - 4s 107us/sample - loss: 0.0355 - accuracy: 0.9883 - val_loss: 0.0937 - val_accuracy: 0.9740\n",
            "Epoch 11/30\n",
            "36667/36667 [==============================] - 4s 107us/sample - loss: 0.0313 - accuracy: 0.9899 - val_loss: 0.0786 - val_accuracy: 0.9790\n",
            "Epoch 12/30\n",
            "36667/36667 [==============================] - 4s 111us/sample - loss: 0.0287 - accuracy: 0.9912 - val_loss: 0.0774 - val_accuracy: 0.9798\n",
            "Epoch 13/30\n",
            "36667/36667 [==============================] - 4s 107us/sample - loss: 0.0254 - accuracy: 0.9919 - val_loss: 0.0846 - val_accuracy: 0.9776\n",
            "Epoch 14/30\n",
            "36667/36667 [==============================] - 4s 109us/sample - loss: 0.0233 - accuracy: 0.9926 - val_loss: 0.0908 - val_accuracy: 0.9766\n",
            "[CV] .................................... n_dropout=0.1, total=  58.7s\n",
            "[CV] n_dropout=0.1 ...................................................\n",
            "Train on 36667 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.3525 - accuracy: 0.8980 - val_loss: 0.1784 - val_accuracy: 0.9492\n",
            "Epoch 2/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.1650 - accuracy: 0.9514 - val_loss: 0.1305 - val_accuracy: 0.9638\n",
            "Epoch 3/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.1188 - accuracy: 0.9649 - val_loss: 0.1017 - val_accuracy: 0.9692\n",
            "Epoch 4/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0923 - accuracy: 0.9729 - val_loss: 0.0921 - val_accuracy: 0.9738\n",
            "Epoch 5/30\n",
            "36667/36667 [==============================] - 4s 113us/sample - loss: 0.0755 - accuracy: 0.9765 - val_loss: 0.0886 - val_accuracy: 0.9730\n",
            "Epoch 6/30\n",
            "36667/36667 [==============================] - 4s 106us/sample - loss: 0.0628 - accuracy: 0.9809 - val_loss: 0.0884 - val_accuracy: 0.9742\n",
            "Epoch 7/30\n",
            "36667/36667 [==============================] - 4s 110us/sample - loss: 0.0512 - accuracy: 0.9836 - val_loss: 0.0804 - val_accuracy: 0.9770\n",
            "Epoch 8/30\n",
            "36667/36667 [==============================] - 4s 106us/sample - loss: 0.0469 - accuracy: 0.9856 - val_loss: 0.0864 - val_accuracy: 0.9764\n",
            "Epoch 9/30\n",
            "36667/36667 [==============================] - 4s 109us/sample - loss: 0.0390 - accuracy: 0.9875 - val_loss: 0.0795 - val_accuracy: 0.9784\n",
            "Epoch 10/30\n",
            "36667/36667 [==============================] - 4s 117us/sample - loss: 0.0365 - accuracy: 0.9875 - val_loss: 0.0769 - val_accuracy: 0.9784\n",
            "Epoch 11/30\n",
            "36667/36667 [==============================] - 4s 106us/sample - loss: 0.0325 - accuracy: 0.9898 - val_loss: 0.0829 - val_accuracy: 0.9772\n",
            "Epoch 12/30\n",
            "36667/36667 [==============================] - 4s 105us/sample - loss: 0.0280 - accuracy: 0.9915 - val_loss: 0.0802 - val_accuracy: 0.9778\n",
            "[CV] .................................... n_dropout=0.1, total=  50.1s\n",
            "[CV] n_dropout=0.15 ..................................................\n",
            "Train on 36666 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36666/36666 [==============================] - 4s 117us/sample - loss: 0.3597 - accuracy: 0.8955 - val_loss: 0.1762 - val_accuracy: 0.9522\n",
            "Epoch 2/30\n",
            "36666/36666 [==============================] - 4s 116us/sample - loss: 0.1746 - accuracy: 0.9498 - val_loss: 0.1261 - val_accuracy: 0.9622\n",
            "Epoch 3/30\n",
            "36666/36666 [==============================] - 4s 111us/sample - loss: 0.1311 - accuracy: 0.9605 - val_loss: 0.1152 - val_accuracy: 0.9646\n",
            "Epoch 4/30\n",
            "36666/36666 [==============================] - 4s 115us/sample - loss: 0.1045 - accuracy: 0.9689 - val_loss: 0.0992 - val_accuracy: 0.9726\n",
            "Epoch 5/30\n",
            "36666/36666 [==============================] - 4s 115us/sample - loss: 0.0877 - accuracy: 0.9729 - val_loss: 0.0960 - val_accuracy: 0.9706\n",
            "Epoch 6/30\n",
            "36666/36666 [==============================] - 4s 111us/sample - loss: 0.0728 - accuracy: 0.9775 - val_loss: 0.0925 - val_accuracy: 0.9728\n",
            "Epoch 7/30\n",
            "36666/36666 [==============================] - 4s 106us/sample - loss: 0.0641 - accuracy: 0.9800 - val_loss: 0.0889 - val_accuracy: 0.9754\n",
            "Epoch 8/30\n",
            "36666/36666 [==============================] - 4s 112us/sample - loss: 0.0555 - accuracy: 0.9815 - val_loss: 0.0846 - val_accuracy: 0.9740\n",
            "Epoch 9/30\n",
            "36666/36666 [==============================] - 4s 111us/sample - loss: 0.0510 - accuracy: 0.9836 - val_loss: 0.0887 - val_accuracy: 0.9746\n",
            "Epoch 10/30\n",
            "36666/36666 [==============================] - 4s 115us/sample - loss: 0.0451 - accuracy: 0.9851 - val_loss: 0.0870 - val_accuracy: 0.9754\n",
            "[CV] ................................... n_dropout=0.15, total=  43.4s\n",
            "[CV] n_dropout=0.15 ..................................................\n",
            "Train on 36667 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36667/36667 [==============================] - 4s 114us/sample - loss: 0.3778 - accuracy: 0.8921 - val_loss: 0.1912 - val_accuracy: 0.9462\n",
            "Epoch 2/30\n",
            "36667/36667 [==============================] - 4s 107us/sample - loss: 0.1828 - accuracy: 0.9464 - val_loss: 0.1364 - val_accuracy: 0.9628\n",
            "Epoch 3/30\n",
            "36667/36667 [==============================] - 4s 105us/sample - loss: 0.1324 - accuracy: 0.9613 - val_loss: 0.1111 - val_accuracy: 0.9662\n",
            "Epoch 4/30\n",
            "36667/36667 [==============================] - 4s 105us/sample - loss: 0.1058 - accuracy: 0.9684 - val_loss: 0.0960 - val_accuracy: 0.9698\n",
            "Epoch 5/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0872 - accuracy: 0.9733 - val_loss: 0.0929 - val_accuracy: 0.9708\n",
            "Epoch 6/30\n",
            "36667/36667 [==============================] - 4s 107us/sample - loss: 0.0721 - accuracy: 0.9779 - val_loss: 0.0836 - val_accuracy: 0.9746\n",
            "Epoch 7/30\n",
            "36667/36667 [==============================] - 4s 107us/sample - loss: 0.0639 - accuracy: 0.9798 - val_loss: 0.0804 - val_accuracy: 0.9744\n",
            "Epoch 8/30\n",
            "36667/36667 [==============================] - 4s 106us/sample - loss: 0.0548 - accuracy: 0.9820 - val_loss: 0.0834 - val_accuracy: 0.9766\n",
            "Epoch 9/30\n",
            "36667/36667 [==============================] - 4s 105us/sample - loss: 0.0482 - accuracy: 0.9840 - val_loss: 0.0871 - val_accuracy: 0.9728\n",
            "[CV] ................................... n_dropout=0.15, total=  37.3s\n",
            "[CV] n_dropout=0.15 ..................................................\n",
            "Train on 36667 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.3709 - accuracy: 0.8937 - val_loss: 0.1798 - val_accuracy: 0.9492\n",
            "Epoch 2/30\n",
            "36667/36667 [==============================] - 4s 113us/sample - loss: 0.1781 - accuracy: 0.9465 - val_loss: 0.1305 - val_accuracy: 0.9642\n",
            "Epoch 3/30\n",
            "36667/36667 [==============================] - 4s 116us/sample - loss: 0.1310 - accuracy: 0.9599 - val_loss: 0.1178 - val_accuracy: 0.9660\n",
            "Epoch 4/30\n",
            "36667/36667 [==============================] - 4s 111us/sample - loss: 0.1036 - accuracy: 0.9689 - val_loss: 0.0946 - val_accuracy: 0.9732\n",
            "Epoch 5/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0864 - accuracy: 0.9726 - val_loss: 0.0887 - val_accuracy: 0.9740\n",
            "Epoch 6/30\n",
            "36667/36667 [==============================] - 4s 106us/sample - loss: 0.0735 - accuracy: 0.9768 - val_loss: 0.0933 - val_accuracy: 0.9730\n",
            "Epoch 7/30\n",
            "36667/36667 [==============================] - 4s 107us/sample - loss: 0.0638 - accuracy: 0.9792 - val_loss: 0.0829 - val_accuracy: 0.9768\n",
            "Epoch 8/30\n",
            "36667/36667 [==============================] - 4s 105us/sample - loss: 0.0554 - accuracy: 0.9815 - val_loss: 0.0797 - val_accuracy: 0.9746\n",
            "Epoch 9/30\n",
            "36667/36667 [==============================] - 4s 109us/sample - loss: 0.0505 - accuracy: 0.9839 - val_loss: 0.0794 - val_accuracy: 0.9776\n",
            "Epoch 10/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0463 - accuracy: 0.9845 - val_loss: 0.0798 - val_accuracy: 0.9776\n",
            "Epoch 11/30\n",
            "36667/36667 [==============================] - 4s 119us/sample - loss: 0.0408 - accuracy: 0.9870 - val_loss: 0.0729 - val_accuracy: 0.9796\n",
            "Epoch 12/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0364 - accuracy: 0.9883 - val_loss: 0.0785 - val_accuracy: 0.9788\n",
            "Epoch 13/30\n",
            "36667/36667 [==============================] - 4s 116us/sample - loss: 0.0335 - accuracy: 0.9886 - val_loss: 0.0851 - val_accuracy: 0.9766\n",
            "[CV] ................................... n_dropout=0.15, total=  54.8s\n",
            "[CV] n_dropout=0.2 ...................................................\n",
            "Train on 36666 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36666/36666 [==============================] - 4s 113us/sample - loss: 0.3764 - accuracy: 0.8905 - val_loss: 0.1810 - val_accuracy: 0.9522\n",
            "Epoch 2/30\n",
            "36666/36666 [==============================] - 4s 108us/sample - loss: 0.1847 - accuracy: 0.9464 - val_loss: 0.1346 - val_accuracy: 0.9606\n",
            "Epoch 3/30\n",
            "36666/36666 [==============================] - 4s 105us/sample - loss: 0.1414 - accuracy: 0.9572 - val_loss: 0.1103 - val_accuracy: 0.9680\n",
            "Epoch 4/30\n",
            "36666/36666 [==============================] - 4s 106us/sample - loss: 0.1146 - accuracy: 0.9642 - val_loss: 0.0992 - val_accuracy: 0.9714\n",
            "Epoch 5/30\n",
            "36666/36666 [==============================] - 4s 109us/sample - loss: 0.0962 - accuracy: 0.9703 - val_loss: 0.0907 - val_accuracy: 0.9724\n",
            "Epoch 6/30\n",
            "36666/36666 [==============================] - 4s 109us/sample - loss: 0.0837 - accuracy: 0.9731 - val_loss: 0.0887 - val_accuracy: 0.9726\n",
            "Epoch 7/30\n",
            "36666/36666 [==============================] - 4s 107us/sample - loss: 0.0731 - accuracy: 0.9762 - val_loss: 0.0893 - val_accuracy: 0.9738\n",
            "Epoch 8/30\n",
            "36666/36666 [==============================] - 4s 105us/sample - loss: 0.0630 - accuracy: 0.9797 - val_loss: 0.0856 - val_accuracy: 0.9746\n",
            "Epoch 9/30\n",
            "36666/36666 [==============================] - 4s 112us/sample - loss: 0.0598 - accuracy: 0.9801 - val_loss: 0.0808 - val_accuracy: 0.9758\n",
            "Epoch 10/30\n",
            "36666/36666 [==============================] - 4s 105us/sample - loss: 0.0526 - accuracy: 0.9831 - val_loss: 0.0869 - val_accuracy: 0.9746\n",
            "Epoch 11/30\n",
            "36666/36666 [==============================] - 4s 114us/sample - loss: 0.0476 - accuracy: 0.9847 - val_loss: 0.0810 - val_accuracy: 0.9758\n",
            "[CV] .................................... n_dropout=0.2, total=  45.8s\n",
            "[CV] n_dropout=0.2 ...................................................\n",
            "Train on 36667 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36667/36667 [==============================] - 4s 115us/sample - loss: 0.3704 - accuracy: 0.8938 - val_loss: 0.1771 - val_accuracy: 0.9498\n",
            "Epoch 2/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.1833 - accuracy: 0.9471 - val_loss: 0.1265 - val_accuracy: 0.9650\n",
            "Epoch 3/30\n",
            "36667/36667 [==============================] - 4s 116us/sample - loss: 0.1364 - accuracy: 0.9590 - val_loss: 0.1102 - val_accuracy: 0.9644\n",
            "Epoch 4/30\n",
            "36667/36667 [==============================] - 4s 115us/sample - loss: 0.1129 - accuracy: 0.9655 - val_loss: 0.0959 - val_accuracy: 0.9702\n",
            "Epoch 5/30\n",
            "36667/36667 [==============================] - 4s 114us/sample - loss: 0.0963 - accuracy: 0.9704 - val_loss: 0.0886 - val_accuracy: 0.9716\n",
            "Epoch 6/30\n",
            "36667/36667 [==============================] - 4s 107us/sample - loss: 0.0792 - accuracy: 0.9758 - val_loss: 0.0879 - val_accuracy: 0.9728\n",
            "Epoch 7/30\n",
            "36667/36667 [==============================] - 4s 111us/sample - loss: 0.0733 - accuracy: 0.9773 - val_loss: 0.0827 - val_accuracy: 0.9746\n",
            "Epoch 8/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0608 - accuracy: 0.9803 - val_loss: 0.0825 - val_accuracy: 0.9754\n",
            "Epoch 9/30\n",
            "36667/36667 [==============================] - 4s 111us/sample - loss: 0.0568 - accuracy: 0.9820 - val_loss: 0.0804 - val_accuracy: 0.9768\n",
            "Epoch 10/30\n",
            "36667/36667 [==============================] - 4s 117us/sample - loss: 0.0525 - accuracy: 0.9830 - val_loss: 0.0899 - val_accuracy: 0.9724\n",
            "Epoch 11/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.0466 - accuracy: 0.9851 - val_loss: 0.0770 - val_accuracy: 0.9786\n",
            "Epoch 12/30\n",
            "36667/36667 [==============================] - 4s 109us/sample - loss: 0.0434 - accuracy: 0.9860 - val_loss: 0.0780 - val_accuracy: 0.9786\n",
            "Epoch 13/30\n",
            "36667/36667 [==============================] - 4s 109us/sample - loss: 0.0409 - accuracy: 0.9860 - val_loss: 0.0795 - val_accuracy: 0.9788\n",
            "[CV] .................................... n_dropout=0.2, total=  55.4s\n",
            "[CV] n_dropout=0.2 ...................................................\n",
            "Train on 36667 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36667/36667 [==============================] - 4s 116us/sample - loss: 0.3822 - accuracy: 0.8884 - val_loss: 0.1764 - val_accuracy: 0.9494\n",
            "Epoch 2/30\n",
            "36667/36667 [==============================] - 4s 110us/sample - loss: 0.1851 - accuracy: 0.9459 - val_loss: 0.1298 - val_accuracy: 0.9628\n",
            "Epoch 3/30\n",
            "36667/36667 [==============================] - 4s 114us/sample - loss: 0.1419 - accuracy: 0.9578 - val_loss: 0.1113 - val_accuracy: 0.9694\n",
            "Epoch 4/30\n",
            "36667/36667 [==============================] - 4s 115us/sample - loss: 0.1160 - accuracy: 0.9652 - val_loss: 0.0971 - val_accuracy: 0.9690\n",
            "Epoch 5/30\n",
            "36667/36667 [==============================] - 4s 106us/sample - loss: 0.0962 - accuracy: 0.9706 - val_loss: 0.0938 - val_accuracy: 0.9714\n",
            "Epoch 6/30\n",
            "36667/36667 [==============================] - 4s 121us/sample - loss: 0.0857 - accuracy: 0.9731 - val_loss: 0.0874 - val_accuracy: 0.9746\n",
            "Epoch 7/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.0747 - accuracy: 0.9757 - val_loss: 0.0883 - val_accuracy: 0.9738\n",
            "Epoch 8/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0653 - accuracy: 0.9789 - val_loss: 0.0874 - val_accuracy: 0.9734\n",
            "Epoch 9/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0590 - accuracy: 0.9815 - val_loss: 0.0843 - val_accuracy: 0.9756\n",
            "Epoch 10/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0526 - accuracy: 0.9819 - val_loss: 0.0890 - val_accuracy: 0.9746\n",
            "Epoch 11/30\n",
            "36667/36667 [==============================] - 4s 107us/sample - loss: 0.0493 - accuracy: 0.9839 - val_loss: 0.0859 - val_accuracy: 0.9756\n",
            "[CV] .................................... n_dropout=0.2, total=  47.1s\n",
            "[CV] n_dropout=0.25 ..................................................\n",
            "Train on 36666 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36666/36666 [==============================] - 4s 119us/sample - loss: 0.3933 - accuracy: 0.8845 - val_loss: 0.1924 - val_accuracy: 0.9450\n",
            "Epoch 2/30\n",
            "36666/36666 [==============================] - 4s 109us/sample - loss: 0.2041 - accuracy: 0.9392 - val_loss: 0.1441 - val_accuracy: 0.9580\n",
            "Epoch 3/30\n",
            "36666/36666 [==============================] - 4s 114us/sample - loss: 0.1553 - accuracy: 0.9529 - val_loss: 0.1227 - val_accuracy: 0.9648\n",
            "Epoch 4/30\n",
            "36666/36666 [==============================] - 4s 108us/sample - loss: 0.1252 - accuracy: 0.9610 - val_loss: 0.1042 - val_accuracy: 0.9686\n",
            "Epoch 5/30\n",
            "36666/36666 [==============================] - 4s 106us/sample - loss: 0.1099 - accuracy: 0.9653 - val_loss: 0.1020 - val_accuracy: 0.9698\n",
            "Epoch 6/30\n",
            "36666/36666 [==============================] - 4s 107us/sample - loss: 0.0952 - accuracy: 0.9698 - val_loss: 0.0946 - val_accuracy: 0.9704\n",
            "Epoch 7/30\n",
            "36666/36666 [==============================] - 4s 110us/sample - loss: 0.0854 - accuracy: 0.9740 - val_loss: 0.0903 - val_accuracy: 0.9740\n",
            "Epoch 8/30\n",
            "36666/36666 [==============================] - 4s 109us/sample - loss: 0.0775 - accuracy: 0.9761 - val_loss: 0.0842 - val_accuracy: 0.9758\n",
            "Epoch 9/30\n",
            "36666/36666 [==============================] - 4s 112us/sample - loss: 0.0708 - accuracy: 0.9762 - val_loss: 0.0827 - val_accuracy: 0.9752\n",
            "Epoch 10/30\n",
            "36666/36666 [==============================] - 4s 116us/sample - loss: 0.0661 - accuracy: 0.9786 - val_loss: 0.0867 - val_accuracy: 0.9774\n",
            "Epoch 11/30\n",
            "36666/36666 [==============================] - 4s 111us/sample - loss: 0.0588 - accuracy: 0.9805 - val_loss: 0.0807 - val_accuracy: 0.9774\n",
            "Epoch 12/30\n",
            "36666/36666 [==============================] - 4s 113us/sample - loss: 0.0563 - accuracy: 0.9814 - val_loss: 0.0860 - val_accuracy: 0.9752\n",
            "Epoch 13/30\n",
            "36666/36666 [==============================] - 4s 112us/sample - loss: 0.0540 - accuracy: 0.9816 - val_loss: 0.0854 - val_accuracy: 0.9752\n",
            "[CV] ................................... n_dropout=0.25, total=  55.2s\n",
            "[CV] n_dropout=0.25 ..................................................\n",
            "Train on 36667 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36667/36667 [==============================] - 4s 120us/sample - loss: 0.3856 - accuracy: 0.8886 - val_loss: 0.1860 - val_accuracy: 0.9492\n",
            "Epoch 2/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.1960 - accuracy: 0.9425 - val_loss: 0.1380 - val_accuracy: 0.9614\n",
            "Epoch 3/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.1499 - accuracy: 0.9553 - val_loss: 0.1079 - val_accuracy: 0.9684\n",
            "Epoch 4/30\n",
            "36667/36667 [==============================] - 4s 107us/sample - loss: 0.1220 - accuracy: 0.9618 - val_loss: 0.1014 - val_accuracy: 0.9714\n",
            "Epoch 5/30\n",
            "36667/36667 [==============================] - 4s 109us/sample - loss: 0.1052 - accuracy: 0.9674 - val_loss: 0.0968 - val_accuracy: 0.9730\n",
            "Epoch 6/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0921 - accuracy: 0.9711 - val_loss: 0.0867 - val_accuracy: 0.9742\n",
            "Epoch 7/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0796 - accuracy: 0.9741 - val_loss: 0.0853 - val_accuracy: 0.9730\n",
            "Epoch 8/30\n",
            "36667/36667 [==============================] - 4s 110us/sample - loss: 0.0729 - accuracy: 0.9768 - val_loss: 0.0848 - val_accuracy: 0.9748\n",
            "Epoch 9/30\n",
            "36667/36667 [==============================] - 4s 111us/sample - loss: 0.0657 - accuracy: 0.9789 - val_loss: 0.0862 - val_accuracy: 0.9762\n",
            "Epoch 10/30\n",
            "36667/36667 [==============================] - 4s 118us/sample - loss: 0.0620 - accuracy: 0.9794 - val_loss: 0.0895 - val_accuracy: 0.9742\n",
            "[CV] ................................... n_dropout=0.25, total=  43.0s\n",
            "[CV] n_dropout=0.25 ..................................................\n",
            "Train on 36667 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36667/36667 [==============================] - 4s 122us/sample - loss: 0.3968 - accuracy: 0.8840 - val_loss: 0.1831 - val_accuracy: 0.9498\n",
            "Epoch 2/30\n",
            "36667/36667 [==============================] - 4s 107us/sample - loss: 0.2038 - accuracy: 0.9398 - val_loss: 0.1352 - val_accuracy: 0.9638\n",
            "Epoch 3/30\n",
            "36667/36667 [==============================] - 4s 109us/sample - loss: 0.1556 - accuracy: 0.9526 - val_loss: 0.1170 - val_accuracy: 0.9664\n",
            "Epoch 4/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.1321 - accuracy: 0.9600 - val_loss: 0.1018 - val_accuracy: 0.9710\n",
            "Epoch 5/30\n",
            "36667/36667 [==============================] - 4s 111us/sample - loss: 0.1082 - accuracy: 0.9671 - val_loss: 0.0943 - val_accuracy: 0.9730\n",
            "Epoch 6/30\n",
            "36667/36667 [==============================] - 4s 109us/sample - loss: 0.0951 - accuracy: 0.9710 - val_loss: 0.0964 - val_accuracy: 0.9716\n",
            "Epoch 7/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0859 - accuracy: 0.9730 - val_loss: 0.0926 - val_accuracy: 0.9732\n",
            "Epoch 8/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.0768 - accuracy: 0.9756 - val_loss: 0.0922 - val_accuracy: 0.9732\n",
            "Epoch 9/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0712 - accuracy: 0.9769 - val_loss: 0.0879 - val_accuracy: 0.9746\n",
            "Epoch 10/30\n",
            "36667/36667 [==============================] - 4s 110us/sample - loss: 0.0638 - accuracy: 0.9787 - val_loss: 0.0838 - val_accuracy: 0.9750\n",
            "Epoch 11/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0604 - accuracy: 0.9799 - val_loss: 0.0891 - val_accuracy: 0.9764\n",
            "Epoch 12/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.0550 - accuracy: 0.9812 - val_loss: 0.0944 - val_accuracy: 0.9770\n",
            "[CV] ................................... n_dropout=0.25, total=  50.7s\n",
            "[CV] n_dropout=0.3 ...................................................\n",
            "Train on 36666 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36666/36666 [==============================] - 4s 121us/sample - loss: 0.4049 - accuracy: 0.8812 - val_loss: 0.1873 - val_accuracy: 0.9462\n",
            "Epoch 2/30\n",
            "36666/36666 [==============================] - 4s 110us/sample - loss: 0.2131 - accuracy: 0.9371 - val_loss: 0.1364 - val_accuracy: 0.9610\n",
            "Epoch 3/30\n",
            "36666/36666 [==============================] - 4s 116us/sample - loss: 0.1637 - accuracy: 0.9518 - val_loss: 0.1173 - val_accuracy: 0.9674\n",
            "Epoch 4/30\n",
            "36666/36666 [==============================] - 4s 109us/sample - loss: 0.1394 - accuracy: 0.9584 - val_loss: 0.1005 - val_accuracy: 0.9726\n",
            "Epoch 5/30\n",
            "36666/36666 [==============================] - 4s 111us/sample - loss: 0.1203 - accuracy: 0.9626 - val_loss: 0.0970 - val_accuracy: 0.9726\n",
            "Epoch 6/30\n",
            "36666/36666 [==============================] - 4s 113us/sample - loss: 0.1056 - accuracy: 0.9677 - val_loss: 0.0967 - val_accuracy: 0.9702\n",
            "Epoch 7/30\n",
            "36666/36666 [==============================] - 4s 109us/sample - loss: 0.0954 - accuracy: 0.9698 - val_loss: 0.0838 - val_accuracy: 0.9740\n",
            "Epoch 8/30\n",
            "36666/36666 [==============================] - 4s 114us/sample - loss: 0.0855 - accuracy: 0.9728 - val_loss: 0.0851 - val_accuracy: 0.9770\n",
            "Epoch 9/30\n",
            "36666/36666 [==============================] - 4s 115us/sample - loss: 0.0795 - accuracy: 0.9743 - val_loss: 0.0839 - val_accuracy: 0.9750\n",
            "[CV] .................................... n_dropout=0.3, total=  39.6s\n",
            "[CV] n_dropout=0.3 ...................................................\n",
            "Train on 36667 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36667/36667 [==============================] - 5s 127us/sample - loss: 0.4022 - accuracy: 0.8810 - val_loss: 0.1903 - val_accuracy: 0.9446\n",
            "Epoch 2/30\n",
            "36667/36667 [==============================] - 4s 113us/sample - loss: 0.2105 - accuracy: 0.9389 - val_loss: 0.1445 - val_accuracy: 0.9592\n",
            "Epoch 3/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.1623 - accuracy: 0.9516 - val_loss: 0.1154 - val_accuracy: 0.9670\n",
            "Epoch 4/30\n",
            "36667/36667 [==============================] - 4s 108us/sample - loss: 0.1355 - accuracy: 0.9586 - val_loss: 0.1051 - val_accuracy: 0.9696\n",
            "Epoch 5/30\n",
            "36667/36667 [==============================] - 4s 110us/sample - loss: 0.1193 - accuracy: 0.9635 - val_loss: 0.0953 - val_accuracy: 0.9714\n",
            "Epoch 6/30\n",
            "36667/36667 [==============================] - 4s 113us/sample - loss: 0.1052 - accuracy: 0.9666 - val_loss: 0.0904 - val_accuracy: 0.9740\n",
            "Epoch 7/30\n",
            "36667/36667 [==============================] - 4s 113us/sample - loss: 0.0963 - accuracy: 0.9688 - val_loss: 0.0855 - val_accuracy: 0.9744\n",
            "Epoch 8/30\n",
            "36667/36667 [==============================] - 4s 115us/sample - loss: 0.0863 - accuracy: 0.9725 - val_loss: 0.0867 - val_accuracy: 0.9764\n",
            "Epoch 9/30\n",
            "36667/36667 [==============================] - 4s 116us/sample - loss: 0.0785 - accuracy: 0.9754 - val_loss: 0.0862 - val_accuracy: 0.9754\n",
            "[CV] .................................... n_dropout=0.3, total=  40.2s\n",
            "[CV] n_dropout=0.3 ...................................................\n",
            "Train on 36667 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "36667/36667 [==============================] - 4s 121us/sample - loss: 0.4009 - accuracy: 0.8817 - val_loss: 0.1770 - val_accuracy: 0.9484\n",
            "Epoch 2/30\n",
            "36667/36667 [==============================] - 4s 113us/sample - loss: 0.2070 - accuracy: 0.9381 - val_loss: 0.1342 - val_accuracy: 0.9616\n",
            "Epoch 3/30\n",
            "36667/36667 [==============================] - 4s 116us/sample - loss: 0.1594 - accuracy: 0.9517 - val_loss: 0.1126 - val_accuracy: 0.9678\n",
            "Epoch 4/30\n",
            "36667/36667 [==============================] - 4s 111us/sample - loss: 0.1350 - accuracy: 0.9587 - val_loss: 0.1014 - val_accuracy: 0.9706\n",
            "Epoch 5/30\n",
            "36667/36667 [==============================] - 4s 110us/sample - loss: 0.1151 - accuracy: 0.9651 - val_loss: 0.0986 - val_accuracy: 0.9728\n",
            "Epoch 6/30\n",
            "36667/36667 [==============================] - 4s 109us/sample - loss: 0.1040 - accuracy: 0.9679 - val_loss: 0.0954 - val_accuracy: 0.9722\n",
            "Epoch 7/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.0935 - accuracy: 0.9707 - val_loss: 0.0902 - val_accuracy: 0.9732\n",
            "Epoch 8/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.0846 - accuracy: 0.9729 - val_loss: 0.0911 - val_accuracy: 0.9748\n",
            "Epoch 9/30\n",
            "36667/36667 [==============================] - 4s 117us/sample - loss: 0.0786 - accuracy: 0.9745 - val_loss: 0.0893 - val_accuracy: 0.9756\n",
            "Epoch 10/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.0741 - accuracy: 0.9756 - val_loss: 0.0973 - val_accuracy: 0.9764\n",
            "Epoch 11/30\n",
            "36667/36667 [==============================] - 4s 114us/sample - loss: 0.0703 - accuracy: 0.9767 - val_loss: 0.0873 - val_accuracy: 0.9772\n",
            "Epoch 12/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.0627 - accuracy: 0.9793 - val_loss: 0.0892 - val_accuracy: 0.9770\n",
            "Epoch 13/30\n",
            "36667/36667 [==============================] - 4s 110us/sample - loss: 0.0611 - accuracy: 0.9788 - val_loss: 0.0870 - val_accuracy: 0.9788\n",
            "Epoch 14/30\n",
            "36667/36667 [==============================] - 4s 112us/sample - loss: 0.0586 - accuracy: 0.9803 - val_loss: 0.0859 - val_accuracy: 0.9782\n",
            "Epoch 15/30\n",
            "36667/36667 [==============================] - 4s 114us/sample - loss: 0.0549 - accuracy: 0.9818 - val_loss: 0.0891 - val_accuracy: 0.9794\n",
            "Epoch 16/30\n",
            "36667/36667 [==============================] - 4s 114us/sample - loss: 0.0538 - accuracy: 0.9822 - val_loss: 0.0883 - val_accuracy: 0.9778\n",
            "[CV] .................................... n_dropout=0.3, total= 1.1min\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=1)]: Done  21 out of  21 | elapsed: 16.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 55000 samples, validate on 5000 samples\n",
            "Epoch 1/30\n",
            "55000/55000 [==============================] - 7s 120us/sample - loss: 0.3198 - accuracy: 0.9070 - val_loss: 0.1463 - val_accuracy: 0.9598\n",
            "Epoch 2/30\n",
            "55000/55000 [==============================] - 6s 115us/sample - loss: 0.1590 - accuracy: 0.9526 - val_loss: 0.1155 - val_accuracy: 0.9662\n",
            "Epoch 3/30\n",
            "55000/55000 [==============================] - 6s 113us/sample - loss: 0.1218 - accuracy: 0.9633 - val_loss: 0.0999 - val_accuracy: 0.9710\n",
            "Epoch 4/30\n",
            "55000/55000 [==============================] - 6s 114us/sample - loss: 0.1011 - accuracy: 0.9695 - val_loss: 0.0888 - val_accuracy: 0.9762\n",
            "Epoch 5/30\n",
            "55000/55000 [==============================] - 6s 107us/sample - loss: 0.0881 - accuracy: 0.9725 - val_loss: 0.0816 - val_accuracy: 0.9770\n",
            "Epoch 6/30\n",
            "55000/55000 [==============================] - 6s 109us/sample - loss: 0.0759 - accuracy: 0.9760 - val_loss: 0.0766 - val_accuracy: 0.9778\n",
            "Epoch 7/30\n",
            "55000/55000 [==============================] - 6s 114us/sample - loss: 0.0679 - accuracy: 0.9784 - val_loss: 0.0723 - val_accuracy: 0.9800\n",
            "Epoch 8/30\n",
            "55000/55000 [==============================] - 6s 113us/sample - loss: 0.0615 - accuracy: 0.9799 - val_loss: 0.0746 - val_accuracy: 0.9794\n",
            "Epoch 9/30\n",
            "55000/55000 [==============================] - 6s 109us/sample - loss: 0.0575 - accuracy: 0.9813 - val_loss: 0.0712 - val_accuracy: 0.9778\n",
            "Epoch 10/30\n",
            "55000/55000 [==============================] - 6s 108us/sample - loss: 0.0543 - accuracy: 0.9820 - val_loss: 0.0720 - val_accuracy: 0.9784\n",
            "Epoch 11/30\n",
            "55000/55000 [==============================] - 6s 109us/sample - loss: 0.0488 - accuracy: 0.9835 - val_loss: 0.0730 - val_accuracy: 0.9786\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(cv=3, error_score=nan,\n",
              "             estimator=<tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x7f79d5901a58>,\n",
              "             iid='deprecated', n_jobs=None,\n",
              "             param_grid={'n_dropout': (0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3)},\n",
              "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
              "             scoring=None, verbose=2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u51f7S0ZM5r",
        "colab_type": "text"
      },
      "source": [
        "##EVALUATE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jj9jykP5hkD",
        "colab_type": "text"
      },
      "source": [
        "### Inspecting the best estimator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmBJMfTB5hkD",
        "colab_type": "text"
      },
      "source": [
        "Let's get the number of neurons that produced the best estimator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_HZWOIe5hkE",
        "colab_type": "code",
        "outputId": "466bd32c-90dc-43da-eaed-5d01e70ce4ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "grid_cv.best_params_"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_dropout': 0.2}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UyxYloQq5hkG",
        "colab_type": "raw"
      },
      "source": [
        "Let's get the rsults to compare the performance of the 100 models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xhkOrfov5hkG",
        "colab_type": "code",
        "outputId": "8254a7e8-1cb8-4664-fbe5-d29a120e070c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        }
      },
      "source": [
        "results = grid_cv.cv_results_\n",
        "results"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'mean_fit_time': array([38.57532223, 35.02270214, 52.35684395, 44.1775624 , 48.41713222,\n",
              "        48.62662633, 48.4961946 ]),\n",
              " 'mean_score_time': array([0.94864575, 0.98161713, 0.99158804, 0.96690671, 1.0049475 ,\n",
              "        1.0106651 , 1.06902782]),\n",
              " 'mean_test_score': array([0.96963638, 0.97134546, 0.97236363, 0.97103633, 0.97432727,\n",
              "        0.9709091 , 0.97067277]),\n",
              " 'param_n_dropout': masked_array(data=[0, 0.05, 0.1, 0.15, 0.2, 0.25, 0.3],\n",
              "              mask=[False, False, False, False, False, False, False],\n",
              "        fill_value='?',\n",
              "             dtype=object),\n",
              " 'params': [{'n_dropout': 0},\n",
              "  {'n_dropout': 0.05},\n",
              "  {'n_dropout': 0.1},\n",
              "  {'n_dropout': 0.15},\n",
              "  {'n_dropout': 0.2},\n",
              "  {'n_dropout': 0.25},\n",
              "  {'n_dropout': 0.3}],\n",
              " 'rank_test_score': array([7, 3, 2, 4, 1, 5, 6], dtype=int32),\n",
              " 'split0_test_score': array([0.9695102 , 0.97109199, 0.97223735, 0.9725101 , 0.97491002,\n",
              "        0.97180104, 0.96923751]),\n",
              " 'split1_test_score': array([0.96972674, 0.97092676, 0.97299951, 0.96879941, 0.97343588,\n",
              "        0.9696722 , 0.96994489]),\n",
              " 'split2_test_score': array([0.9696722 , 0.97201765, 0.97185403, 0.97179949, 0.9746359 ,\n",
              "        0.97125405, 0.9728359 ]),\n",
              " 'std_fit_time': array([ 2.075345  ,  1.89955499,  3.87001078,  7.24421589,  4.24544701,\n",
              "         5.00760807, 13.67187531]),\n",
              " 'std_score_time': array([0.0462012 , 0.05143208, 0.04527203, 0.00959005, 0.02259687,\n",
              "        0.02920574, 0.0240988 ]),\n",
              " 'std_test_score': array([9.19609466e-05, 4.80066435e-04, 4.76090130e-04, 1.60812674e-03,\n",
              "        6.40163725e-04, 9.02675018e-04, 1.55658913e-03])}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNoNkMU15hkL",
        "colab_type": "code",
        "outputId": "8164dfd1-e15b-40fb-b3c6-6617743d85da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "results['params'], results['rank_test_score']"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([{'n_dropout': 0},\n",
              "  {'n_dropout': 0.05},\n",
              "  {'n_dropout': 0.1},\n",
              "  {'n_dropout': 0.15},\n",
              "  {'n_dropout': 0.2},\n",
              "  {'n_dropout': 0.25},\n",
              "  {'n_dropout': 0.3}],\n",
              " array([7, 3, 2, 4, 1, 5, 6], dtype=int32))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRS71YiS5hkN",
        "colab_type": "code",
        "outputId": "60a6d4ff-5972-4d82-8b5f-b5d1f542bc56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        }
      },
      "source": [
        "best_model = grid_cv.best_estimator_.model\n",
        "keras.utils.plot_model(best_model, show_shapes=True)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHakmEh-5hkP",
        "colab_type": "code",
        "outputId": "15982902-ed6b-484c-c8cd-0844a7482392",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "best_model.evaluate(test_images, test_labels)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07647609669162193, 0.9771]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    }
  ]
}